{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem.snowball import ItalianStemmer\n",
    "import nltk\n",
    "from num2words import num2words\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development dataset:\n",
      "\n",
      "Shape: (28754, 2)\n",
      "\n",
      "Values counts:\n",
      "pos    19532\n",
      "neg     9222\n",
      "Name: class, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Evaluation dataset:\n",
      "\n",
      "Shape: (12323, 1)\n"
     ]
    }
   ],
   "source": [
    "dev = pd.read_csv('exam_development.csv')\n",
    "eval = pd.read_csv('exam_evaluation.csv')\n",
    "\n",
    "print(\"Development dataset:\\n\")\n",
    "print(\"Shape: \" + str(dev.shape) + \"\\n\")\n",
    "print(\"Values counts:\\n\" + str(dev.loc[:, \"class\"].value_counts()) + \"\\n\\n\\n\")\n",
    "\n",
    "print(\"Evaluation dataset:\\n\")\n",
    "print(\"Shape: \" + str(eval.shape))\n",
    "\n",
    "dict = dev.loc[:, \"class\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development dataset\n",
      "-  -  -  -  -  -  -  -  -\n",
      "Lower case text\n",
      "Remove punctuation\n",
      "Remove italian stopwords\n",
      "Stemming process\n",
      "- - - - - - - - - - - -\n",
      "Evaluation dataset\n",
      "-  -  -  -  -  -  -  -  -\n",
      "Lower case text\n",
      "Remove punctuation\n",
      "Remove italian stopwords\n",
      "Stemming process\n"
     ]
    }
   ],
   "source": [
    "# Stemmer\n",
    "stemmer = ItalianStemmer()\n",
    "\n",
    "print(\"Development dataset\")\n",
    "print(\"-  -  -  -  -  -  -  -  -\")\n",
    "print(\"Lower case text\")\n",
    "dev.loc[:, \"text\"] = dev.text.apply(lambda x: str.lower(x).replace(\"'\", \" \"))\n",
    "\n",
    "print(\"Remove punctuation\")\n",
    "dev.loc[:, \"text\"] = dev.text.apply(lambda x: \" \".join(re.findall('[\\w]+', x)))\n",
    "\n",
    "print(\"Remove italian stopwords\")\n",
    "dev.loc[:, \"text\"] = dev.text.apply(lambda x: removeStopWords(x))\n",
    "\n",
    "print(\"Stemming process\")\n",
    "dev.loc[:, \"text\"] = dev.text.apply(lambda x: stem(x))\n",
    "\n",
    "print(\"- - - - - - - - - - - -\")\n",
    "\n",
    "print(\"Evaluation dataset\")\n",
    "print(\"-  -  -  -  -  -  -  -  -\")\n",
    "\n",
    "print(\"Lower case text\")\n",
    "eval.loc[:, \"text\"] = eval.text.apply(lambda x: str.lower(x).replace(\"'\", \" \"))\n",
    "\n",
    "print(\"Remove punctuation\")\n",
    "eval.loc[:, \"text\"] = eval.text.apply(lambda x: \" \".join(re.findall('[\\w]+', x)))\n",
    "\n",
    "print(\"Remove italian stopwords\")\n",
    "eval.loc[:, \"text\"] = eval.text.apply(lambda x: removeStopWords(x))\n",
    "\n",
    "print(\"Stemming process\")\n",
    "eval.loc[:, \"text\"] = eval.text.apply(lambda x: stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit and Predict:\n",
      "Accuracy for C:0.5 \n",
      "(accuracy_score):0.9680055642496957\n",
      "(f1_score): 0.9679298239468118\n",
      "Accuracy for C:1 \n",
      "(accuracy_score):0.9680055642496957\n",
      "(f1_score): 0.9679298239468118\n",
      "Accuracy for C:5 \n",
      "(accuracy_score):0.9680055642496957\n",
      "(f1_score): 0.9679298239468118\n",
      "Accuracy for C:10 \n",
      "(accuracy_score):0.9680055642496957\n",
      "(f1_score): 0.9679298239468118\n",
      "\n",
      "\n",
      "Best positive words:\n",
      "('perfett', 4.315061287108056)\n",
      "('eccellent', 4.122722642589093)\n",
      "('fantast', 3.511618121202611)\n",
      "('confortevol', 3.191626867207938)\n",
      "('po', 3.187816105687944)\n",
      "\n",
      "Best negative words:\n",
      "('pessim', -4.904545308063406)\n",
      "('sporc', -4.551094328473539)\n",
      "('scars', -3.9961653985313177)\n",
      "('scortes', -3.7267099986243837)\n",
      "('vecc', -3.3512247498507683)\n"
     ]
    }
   ],
   "source": [
    "# Local training\n",
    "cv = TfidfVectorizer(ngram_range=(1, 2), binary=True, max_df=0.3)\n",
    "cv.fit(dev.loc[:, \"text\"])\n",
    "X = cv.transform(dev.loc[:, \"text\"])\n",
    "\n",
    "print(\"Fit and Predict:\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dev.loc[:, \"class\"], test_size=0.2, random_state=0)\n",
    "\n",
    "for c in [0.5, 1, 5, 10]:\n",
    "    lr = svm.LinearSVC(class_weight=dict, C=c, max_iter=15000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    predictions = lr.predict(X_test)\n",
    "    print(\"Accuracy for C:%s \\n(accuracy_score):%s\"\n",
    "          % (c, accuracy_score(y_test, predictions)))\n",
    "    print(\"(f1_score):\", f1_score(y_test, predictions, average='weighted'))\n",
    "\n",
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), lr.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"\\n\\nBest positive words:\")\n",
    "for best_positive in sorted(\n",
    "        feature_to_coef.items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True)[:5]:\n",
    "    print(best_positive)\n",
    "print(\"\\nBest negative words:\")\n",
    "for best_negative in sorted(\n",
    "        feature_to_coef.items(),\n",
    "        key=lambda x: x[1])[:5]:\n",
    "    print(best_negative)\n",
    "\n",
    "cv = TfidfVectorizer(ngram_range=(1, 2), max_df=0.3)\n",
    "cv.fit(dev.loc[:, \"text\"])\n",
    "X = cv.transform(dev.loc[:, \"text\"])\n",
    "X_test = cv.transform(eval.loc[:, \"text\"])\n",
    "\n",
    "lr = svm.LinearSVC(class_weight=dict, max_iter=15000)\n",
    "lr.fit(X, dev.loc[:, \"class\"])\n",
    "\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "with open('exam_export.csv', 'w') as file:\n",
    "    file.write(\"Id,Predicted\\n\")\n",
    "    for index in eval.index:\n",
    "        s = predictions[index]\n",
    "        file.write(str(index) + \",\" + s + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('italian')\n",
    "\n",
    "def removeStopWords(s):\n",
    "    s = ' '.join(word for word in s.split() if word not in stopWords)\n",
    "    return s\n",
    "\n",
    "def stem(s):\n",
    "    global stemmer\n",
    "    s = ' '.join(stemmer.stem(word) for word in s.split())\n",
    "    return s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
